{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oneir0mancer/stable-diffusion-diffusers-colab-ui/blob/main/sd_diffusers_img2img_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x-z4MGy9rz9I"
      },
      "outputs": [],
      "source": [
        "#@title #Install dependencies\n",
        "!git clone https://github.com/oneir0mancer/stable-diffusion-diffusers-colab-ui.git StableDiffusionUi\n",
        "\n",
        "!pip install -r StableDiffusionUi/requirements.txt\n",
        "!wget https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
        "\n",
        "!mkdir -p outputs/{txt2img,img2img}\n",
        "!git clone https://huggingface.co/embed/negative /content/embeddings/negative\n",
        "!git clone https://huggingface.co/embed/lora /content/Lora/positive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRvNp3ElcaA3"
      },
      "source": [
        "# Creating model pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVlvLpShS9eo"
      },
      "source": [
        "\n",
        "<details>\n",
        "<summary><b>Description</b><br>TLDR: use dropdown or just paste</summary>\n",
        "\n",
        "---\n",
        "\n",
        "You can just choose a model from a dropdown of popular models, which will also give you a link to a model page on [huggingface](https://huggingface.co) and any trigger words you need to use in the prompt.\n",
        "\n",
        "Alternatively, you can paste a model_id, url, or local path for any model from huggingface:\n",
        "\n",
        "* **model_id** looks like this: `gsdf/Counterfeit-V2.5`.\n",
        "<br>You can use it for any *proper* diffusers model in huggingface, i.e. ones that have a lot of folders in their **Files**, and a file called **model_index.json**\n",
        "<br> `A1111 format` toggle should be **<font color= 'red'>off</font>**.\n",
        "\n",
        "* **url** from HuggingFace may look like this:\n",
        "```\n",
        "https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix/AbyssOrangeMix.safetensors\n",
        "```\n",
        "Use it when the model is in Automatic1111 format (as in, just a single file).\n",
        "<br> `✅ A1111 format` toggle should be **<font color= 'green'>on</font>**.\n",
        "\n",
        "* **url** from CivitAI should look like this:\n",
        "```\n",
        "https://civitai.com/api/download/models/XXXXXX\n",
        "```\n",
        "(the link you get from \"Download\" button)\n",
        "<br> `✅ A1111 format` toggle should be **<font color= 'green'>on</font>**.\n",
        "\n",
        "* **local path** is just a path to a model folder (if diffusers format) or model file (if A1111 format).\n",
        "<br>Set toggle accordingly.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dviyU3E6jK01"
      },
      "source": [
        "<details>\n",
        "<summary>Where to find urls</summary>\n",
        "\n",
        "A good place to find model urls is  [camenduru colabs repo](https://https://github.com/camenduru/stable-diffusion-webui-colab), just look for a line starting with `!aria2c ...`\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k_TR5dUwznN9"
      },
      "outputs": [],
      "source": [
        "#@title Render model choice UI\n",
        "from StableDiffusionUi.ColabUI.ColabWrapper import ColabWrapper\n",
        "\n",
        "colab = ColabWrapper(\"outputs/img2img\")\n",
        "colab.render_model_index(\"/content/StableDiffusionUi/model_index.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IBdm3HvI02Yo"
      },
      "outputs": [],
      "source": [
        "#@title Load chosen model\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "colab.load_model(StableDiffusionImg2ImgPipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWqvp4vYeM_W"
      },
      "source": [
        "## Optional stuff:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9i7ZbasUpTh7"
      },
      "outputs": [],
      "source": [
        "#@title Change sampler\n",
        "choose_sampler = \"DPM++ Karras\" #@param [\"Euler A\", \"DPM++\", \"DPM++ Karras\", \"UniPC\"]\n",
        "colab.choose_sampler(choose_sampler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEwlf_SQXCyt"
      },
      "source": [
        "### VAE\n",
        "\n",
        "Most models come with their own VAE, but changing it may improve generation results. Especially if you get a lot of artifacts or just black images.\n",
        "\n",
        "You can load VAE from any [huggingface](https://huggingface.co) repository, just paste their **model_id** and subfolder (usually just \"vae\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8jKsuQ9E5eCK"
      },
      "outputs": [],
      "source": [
        "#@markdown ##(Optional) Load VAE\n",
        "\n",
        "vae_id_or_path = \"waifu-diffusion/wd-1-5-beta2\"  #@param {type: \"string\"}\n",
        "vae_subfolder = \"vae\"    #@param {type: \"string\"}\n",
        "\n",
        "colab.load_vae(vae_id_or_path, vae_subfolder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY0xKEW2lgmj"
      },
      "source": [
        "### Textual inversions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDQSRzWg5OKU"
      },
      "source": [
        "You can load any textual inversions using\n",
        "```\n",
        "pipe.load_textual_inversion(\"path/to/dir\", weight_name=\"filename.pt\")\n",
        "```\n",
        "To use them, you need to add theit token to a prompt like this `<filename>`.\n",
        "\n",
        "Note that you need to reload textual inversions every time you switch VAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VVU2Rjpb085a"
      },
      "outputs": [],
      "source": [
        "#@markdown ###(Optional) Load textual inversions\n",
        "#@markdown Load every embedding with **.pt** extension from **embeddings** folder.\n",
        "\n",
        "colab.load_textual_inversions(\"/content/embeddings/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYurBnHCbZ3o"
      },
      "source": [
        "### LoRA\n",
        "Work in progress. If anything breaks you can use `colab.pipe` and instructions from [here](https://huggingface.co/docs/diffusers/main/en/tutorials/using_peft_for_inference)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ####Render Lora loader\n",
        "colab.render_lora_loader()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sGcJz--5RbI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ####Render Lora UI\n",
        "colab.render_lora_ui()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dGlN98_iReXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLmzZmRIZMpC"
      },
      "source": [
        "# Generating images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oFruEVcl4ODt"
      },
      "outputs": [],
      "source": [
        "#@title Render UI\n",
        "#@markdown You don't need to run this cell again unless you want to change these settings\n",
        "save_images = True #@param {type:\"boolean\"}\n",
        "display_previewes = True    #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "from  StableDiffusionUi.ColabUI.DiffusionImg2ImgUI import DiffusionImg2ImgUI\n",
        "\n",
        "ui = DiffusionImg2ImgUI()\n",
        "colab.render_generation_ui(ui)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y43YLjY7F7NI"
      },
      "outputs": [],
      "source": [
        "#@title <font color='red'>Run</font> this cell to generate images\n",
        "colab.generate(save_images, display_previewes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gthYZKknKsw7"
      },
      "source": [
        "#Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9vn2Z5tNIAiv"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Image viewer\n",
        "#@markdown Run this cell to view last results in full size\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "slider = widgets.IntSlider(max=len(results.images)-1)\n",
        "\n",
        "def handler(change):\n",
        "    slider.max = len(results.images)-1\n",
        "    if change.new > slider.max: change.new = slider.max\n",
        "    clear_output(wait=True)\n",
        "    display(slider, results.images[change.new])\n",
        "\n",
        "slider.observe(handler, names='value')\n",
        "\n",
        "display(slider, results.images[slider.value])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRUTJXoBc4tG"
      },
      "source": [
        "## Converting models from ckpt\n",
        "You shouldn't really need this, because diffusers now support loading from A1111 format.\n",
        "\n",
        "But if you want, you can download a model and convert it to diffusers format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av9urfOqi7Ak"
      },
      "source": [
        "NOTE: A good place to find model urls is  [camenduru colabs repo](https://https://github.com/camenduru/stable-diffusion-webui-colab), just look for a line starting with `!aria2c ...`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w1JZPBKId6Zv"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Download ckpt file\n",
        "#@markdown Download ckpt/safetensors file from huggingface url.\n",
        "\n",
        "#@markdown ---\n",
        "import os\n",
        "\n",
        "url = \"https://huggingface.co/mekabu/MagicalMix_v2/resolve/main/MagicalMix_v2.safetensors\" #@param {type:\"string\"}\n",
        "ckpt_dump_folder = \"/content/models_sd/\"    #@param {type:\"string\"}\n",
        "model_name = url.split('/')[-1]\n",
        "\n",
        "os.system(f\"mkdir -p {ckpt_dump_folder}\")\n",
        "bashCommand = f\"wget {url} -P {ckpt_dump_folder} --content-disposition\"\n",
        "os.system(bashCommand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dOn6tR_4eJ8k"
      },
      "outputs": [],
      "source": [
        "#@markdown ##(Optional) Or just upload file\n",
        "from google.colab import files\n",
        "f = files.upload()\n",
        "\n",
        "ckpt_dump_folder = \"/content/\"\n",
        "for key in f.keys():\n",
        "    model_name = key\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N1GOOJrej6tW"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Run conversion script\n",
        "#@markdown Paste a path to where you want this script to cache a model into `dump_path`.\n",
        "\n",
        "#@markdown Keep `override_path` empty unless you uploaded your file to some custom directory.\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from diffusers.pipelines.stable_diffusion.convert_from_ckpt import download_from_original_stable_diffusion_ckpt\n",
        "\n",
        "from_safetensors = True #@param {type:\"boolean\"}\n",
        "override_path = \"\" #@param {type:\"string\"}\n",
        "if override_path != \"\":\n",
        "    checkpoint_path = override_path\n",
        "else:\n",
        "    checkpoint_path = os.path.join(ckpt_dump_folder, model_name)\n",
        "\n",
        "pipe = download_from_original_stable_diffusion_ckpt(\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        original_config_file = \"/content/v1-inference.yaml\",\n",
        "        from_safetensors=from_safetensors,\n",
        "    )\n",
        "\n",
        "dump_path=\"models/ModelName/\" #@param {type:\"string\"}\n",
        "pipe.save_pretrained(dump_path, safe_serialization=from_safetensors)\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.safety_checker = None\n",
        "pipe.to(torch_dtype=torch.float16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii9UDlWQnIhg"
      },
      "source": [
        "## Converting VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "916cyCYPnNVt"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Download vae file\n",
        "#@markdown Basically, the same thing as model files\n",
        "\n",
        "#@markdown ---\n",
        "import os\n",
        "\n",
        "url = \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\" #@param {type:\"string\"}\n",
        "ckpt_dump_folder = \"/content/models_sd/\"    #@param {type:\"string\"}\n",
        "model_name = url.split('/')[-1]\n",
        "\n",
        "os.system(f\"mkdir -p {ckpt_dump_folder}\")\n",
        "bashCommand = f\"wget {url} -P {ckpt_dump_folder} --content-disposition\"\n",
        "os.system(bashCommand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dWC8UpJ3m8Fa"
      },
      "outputs": [],
      "source": [
        "#@markdown Paste a path to where you want this script to cache a vae into `dump_path`.\n",
        "from_safetensors = False #@param {type:\"boolean\"}\n",
        "dump_path=\"vae/VaeName/\" #@param {type:\"string\"}\n",
        "\n",
        "checkpoint_path = os.path.join(ckpt_dump_folder, model_name)\n",
        "bashCommand = f\"python /content/StableDiffusionUi/scripts/convert_vae_pt_to_diffusers.py --vae_pt_path {checkpoint_path} --dump_path {dump_path}\"\n",
        "if from_safetensors:\n",
        "    bashCommand += \" --from_safetensors\"\n",
        "os.system(bashCommand)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hEwlf_SQXCyt",
        "mY0xKEW2lgmj",
        "lYurBnHCbZ3o",
        "kRUTJXoBc4tG",
        "ii9UDlWQnIhg"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}