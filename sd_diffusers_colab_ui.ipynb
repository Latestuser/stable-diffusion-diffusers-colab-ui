{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "mY0xKEW2lgmj"
      ],
      "authorship_tag": "ABX9TyOm0gNKLD4JFRCaY/k1t0us",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oneir0mancer/stable-diffusion-diffusers-colab-ui/blob/main/sd_diffusers_colab_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-z4MGy9rz9I",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title #Install dependencies\n",
        "!pip install --upgrade diffusers accelerate transformers xformers safetensors\n",
        "!mkdir -p outputs/{txt2img,img2img}\n",
        "!git clone https://github.com/oneir0mancer/stable-diffusion-diffusers-colab-ui.git StableDiffusionUi\n",
        "!git clone https://huggingface.co/embed/negative /content/embeddings/negative\n",
        "!git clone https://huggingface.co/embed/lora /content/Lora/positive\n",
        "\n",
        "import torch\n",
        "output_index = 0\n",
        "cache = None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating model pipeline\n",
        "You can use most from [huggingface](https://huggingface.co). Just make sure they are in diffusers format, check their **Files** and see if there is a `model_index.json`.\n",
        "\n",
        "I made a simple index wih popular models, so you can just render UI and choose a model from dropdown. Some models require trigger word in the prompt.\n",
        "\n",
        "For weights in Automatic111 format (**.ckpt** or **.safetensors** but without model_index.json), you'll need to download them and [convert using scripts](#scrollTo=kRUTJXoBc4tG)."
      ],
      "metadata": {
        "id": "dVlvLpShS9eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Render model choice UI\n",
        "from StableDiffusionUi.ColabUI.HugginfaceModelIndex import HugginfaceModelIndex\n",
        "\n",
        "model_index = HugginfaceModelIndex(\"/content/StableDiffusionUi/model_index.json\")\n",
        "model_index.render()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "k_TR5dUwznN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load chosen model\n",
        "#@markdown Alternatively you can just paste huggingface model_id or path to model folder here:\n",
        "\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "path_to_model = \"\"  #@param {type: \"string\"}\n",
        "\n",
        "if path_to_model != \"\": model_id = path_to_model\n",
        "else: model_id = model_index.get_model_id()\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(model_id,\n",
        "                                         custom_pipeline=\"lpw_stable_diffusion\", \n",
        "                                         torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.safety_checker = None\n",
        "pipe.enable_xformers_memory_efficient_attention()"
      ],
      "metadata": {
        "id": "IBdm3HvI02Yo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Technical detail</summary>\n",
        "\n",
        "I use [this](https://github.com/huggingface/diffusers/tree/main/examples/community#long-prompt-weighting-stable-diffusion) custom pipeline which doesn't have a token length limit and allows to use weights in prompt.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "pAJzkJWpeOxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Change sampler \n",
        "from diffusers import EulerAncestralDiscreteScheduler, DPMSolverMultistepScheduler, UniPCMultistepScheduler\n",
        "\n",
        "choose_sampler = \"Euler A\" #@param [\"Euler A\", \"DPM++\", \"DPM++ Karras\", \"UniPC\"]\n",
        "\n",
        "if choose_sampler == \"Euler A\":\n",
        "    solver = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "elif choose_sampler == \"DPM++\":\n",
        "    solver = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "elif choose_sampler == \"DPM++ Karras\":\n",
        "    solver = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "    solver.use_karras_sigmas = True\n",
        "elif choose_sampler == \"UniPC\":\n",
        "    solver = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "pipe.scheduler = solver\n",
        "print(f\"Sampler '{choose_sampler}' chosen\")"
      ],
      "metadata": {
        "id": "9i7ZbasUpTh7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE\n",
        "\n",
        "Models loaded from huggingface should have proper VAE. But you also can load VAE from any other repository from [huggingface](https://huggingface.co), just paste their **model_id** and subfolder (usually just \"vae\"). \n",
        "\n",
        "Or you can load it in Automatic111 format and [convert using scripts](#scrollTo=ii9UDlWQnIhg)."
      ],
      "metadata": {
        "id": "hEwlf_SQXCyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Load VAE\n",
        "\n",
        "from diffusers import AutoencoderKL\n",
        "\n",
        "vae_id_or_path = \"runwayml/stable-diffusion-v1-5\"  #@param {type: \"string\"}\n",
        "vae_subfolder = \"vae\"    #@param {type: \"string\"}\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(vae_id_or_path, subfolder=vae_subfolder, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.vae = vae"
      ],
      "metadata": {
        "id": "8jKsuQ9E5eCK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Textual inversions"
      ],
      "metadata": {
        "id": "mY0xKEW2lgmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can load any textual inversions using \n",
        "```\n",
        "pipe.load_textual_inversion(\"path/to/dir\", weight_name=\"filename.pt\")\n",
        "```\n",
        "To use them, you need to add theit token to a prompt like this `<filename>`.\n",
        "\n",
        "Note that you need to reload textual inversions every time you switch VAE."
      ],
      "metadata": {
        "id": "VDQSRzWg5OKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Load textual inversions\n",
        "#@markdown Load every embedding with **.pt** extension from **embeddings** folder.\n",
        "\n",
        "import os\n",
        "\n",
        "for path, subdirs, files in os.walk(\"/content/embeddings/\"):\n",
        "    for name in files:\n",
        "        try:\n",
        "            if os.path.splitext(name)[1] != \".pt\": continue\n",
        "            pipe.load_textual_inversion(path, weight_name=name)\n",
        "            print(path, name)\n",
        "        except: pass"
      ],
      "metadata": {
        "id": "VVU2Rjpb085a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LoRA"
      ],
      "metadata": {
        "id": "lYurBnHCbZ3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell once to setup LoRAs for pipeline\n",
        "import StableDiffusionUi.utils.kohya_lora_loader as kohya_lora_loader\n",
        "\n",
        "kohya_lora_loader.install_lora_hook(pipe)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4ctskUGuckRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lora support is somewhat limited, and they make generation noticeably slower.\n",
        "\n",
        "To use it, upload lora, and apply it using\n",
        "```python\n",
        "lora = pipe.apply_lora('/path/to/lora.safetensors')\n",
        "```\n",
        "To remove it, run\n",
        "```python\n",
        "pipe.remove_lora(lora)\n",
        "```\n",
        "\n",
        "<details>\n",
        "<summary>Technical detail</summary>\n",
        "\n",
        "I'll use LoRA loader script from [here](https://gist.github.com/takuma104/e38d683d72b1e448b8d9b3835f7cfa44) until default diffusers loader works properly.\n",
        "\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "3ERA2tR6bf-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating images"
      ],
      "metadata": {
        "id": "hLmzZmRIZMpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Render UI\n",
        "#@markdown You don't need to run this cell again unless you want to change these settings\n",
        "save_images = True #@param {type:\"boolean\"}\n",
        "display_previewes = True    #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "from  StableDiffusionUi.ColabUI.DiffusionPipelineUI import DiffusionPipelineUI\n",
        "\n",
        "ui = DiffusionPipelineUI()\n",
        "if (cache is not None):\n",
        "    ui.load_cache(cache)\n",
        "\n",
        "ui.render()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oFruEVcl4ODt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color='red'>Run</font> this cell to generate images\n",
        "cache = ui.get_dict_to_cache()\n",
        "\n",
        "results = ui.generate(pipe)\n",
        "if save_images:\n",
        "    for i, image in enumerate(results.images):\n",
        "        path = f\"outputs/txt2img/{output_index:05}.png\"\n",
        "        ui.save_image_with_metadata(image, path, f\"Batch: {i}\\n\")\n",
        "        print(path)\n",
        "        output_index += 1\n",
        "\n",
        "if display_previewes:\n",
        "    ui.display_image_previews(results.images)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y43YLjY7F7NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utils"
      ],
      "metadata": {
        "id": "gthYZKknKsw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image viewer\n",
        "#@markdown Run this cell to view last results in full size\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "slider = widgets.IntSlider(max=len(results.images)-1)\n",
        "\n",
        "def handler(change):\n",
        "    slider.max = len(results.images)-1\n",
        "    if change.new > slider.max: change.new = slider.max\n",
        "    clear_output(wait=True)\n",
        "    display(slider, results.images[change.new])\n",
        "\n",
        "slider.observe(handler, names='value')\n",
        "\n",
        "display(slider, results.images[slider.value])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9vn2Z5tNIAiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting models from ckpt\n",
        "A lot of models from huggingface/civitai use ckpt/safetensors format, that is not supported by diffusers pipelines.\n",
        "\n",
        "So we want to download them, and then convert to diffusers format using conversion scripts. That will allow us to load them, using [this cell](#scrollTo=IBdm3HvI02Yo).\n",
        "\n",
        "If after conversion results look bad, try changing sampler."
      ],
      "metadata": {
        "id": "kRUTJXoBc4tG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "#@markdown You may need to restart runtime after that: `Runtime -> Restart Runtime`\n",
        "!wget https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
        "!apt -y install -qq aria2\n",
        "!pip install pytorch-lightning\n",
        "!pip install omegaconf"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OUqWojdfc_P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: A good place to find model urls is  [camenduru colabs repo](https://https://github.com/camenduru/stable-diffusion-webui-colab), just look for a line starting with `!aria2c ...`\n"
      ],
      "metadata": {
        "id": "av9urfOqi7Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download ckpt file\n",
        "#@markdown Download ckpt/safetensors file from huggingface url. \n",
        "\n",
        "#@markdown ---\n",
        "import os\n",
        "\n",
        "url = \"https://huggingface.co/mekabu/MagicalMix_v2/resolve/main/MagicalMix_v2.safetensors\" #@param {type:\"string\"}\n",
        "ckpt_dump_folder = \"/content/models_sd/\"    #@param {type:\"string\"}\n",
        "model_name = url.split('/')[-1]\n",
        "\n",
        "bashCommand = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url} -d {ckpt_dump_folder} -o {model_name}\"\n",
        "os.system(bashCommand)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "w1JZPBKId6Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Or just upload file\n",
        "from google.colab import files\n",
        "f = files.upload()\n",
        "\n",
        "ckpt_dump_folder = \"/content/\"\n",
        "for key in f.keys():\n",
        "    model_name = key\n",
        "    break"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dOn6tR_4eJ8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run conversion script\n",
        "#@markdown Paste a path to where you want this script to cache a model into `dump_path`.\n",
        "\n",
        "#@markdown Keep `override_path` empty unless you uploaded your file to some custom directory.\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from diffusers.pipelines.stable_diffusion.convert_from_ckpt import download_from_original_stable_diffusion_ckpt\n",
        "\n",
        "from_safetensors = True #@param {type:\"boolean\"}\n",
        "override_path = \"\" #@param {type:\"string\"}\n",
        "if override_path != \"\":\n",
        "    checkpoint_path = override_path\n",
        "else:\n",
        "    checkpoint_path = os.path.join(ckpt_dump_folder, model_name)\n",
        "\n",
        "pipe = download_from_original_stable_diffusion_ckpt(\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        original_config_file = \"/content/v1-inference.yaml\",\n",
        "        from_safetensors=from_safetensors,\n",
        "    )\n",
        "\n",
        "dump_path=\"models/ModelName/\" #@param {type:\"string\"}\n",
        "pipe.save_pretrained(dump_path, safe_serialization=from_safetensors)\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.safety_checker = None\n",
        "pipe.to(torch_dtype=torch.float16)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N1GOOJrej6tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Converting VAE\n"
      ],
      "metadata": {
        "id": "ii9UDlWQnIhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Download vae file\n",
        "#@markdown Basically, the same thing as model files\n",
        "\n",
        "#@markdown ---\n",
        "import os\n",
        "\n",
        "url = \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\" #@param {type:\"string\"}\n",
        "ckpt_dump_folder = \"/content/models_sd/\"    #@param {type:\"string\"}\n",
        "model_name = url.split('/')[-1]\n",
        "\n",
        "bashCommand = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url} -d {ckpt_dump_folder} -o {model_name}\"\n",
        "os.system(bashCommand)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "916cyCYPnNVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Paste a path to where you want this script to cache a vae into `dump_path`.\n",
        "from_safetensors = False #@param {type:\"boolean\"}\n",
        "dump_path=\"vae/VaeName/\" #@param {type:\"string\"}\n",
        "\n",
        "checkpoint_path = os.path.join(ckpt_dump_folder, model_name)\n",
        "bashCommand = f\"python /content/StableDiffusionUi/scripts/convert_vae_pt_to_diffusers.py --vae_pt_path {checkpoint_path} --dump_path {dump_path}\"\n",
        "if from_safetensors:\n",
        "    bashCommand += \" --from_safetensors\"\n",
        "os.system(bashCommand)"
      ],
      "metadata": {
        "id": "dWC8UpJ3m8Fa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}