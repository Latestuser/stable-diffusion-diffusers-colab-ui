{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "hEwlf_SQXCyt",
        "mY0xKEW2lgmj",
        "lYurBnHCbZ3o",
        "kRUTJXoBc4tG",
        "ii9UDlWQnIhg"
      ],
      "authorship_tag": "ABX9TyNySJ3US9kzkeYtdz+jt5K/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oneir0mancer/stable-diffusion-diffusers-colab-ui/blob/main/sd_diffusers_colab_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-z4MGy9rz9I",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title #Install dependencies\n",
        "#@markdown You will need to restart runtime after that: `Runtime -> Restart Runtime`\n",
        "!pip install --upgrade diffusers accelerate transformers xformers safetensors\n",
        "!pip install pytorch-lightning omegaconf\n",
        "!apt -y install -qq aria2\n",
        "!wget https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
        "\n",
        "!mkdir -p outputs/{txt2img,img2img}\n",
        "!git clone https://github.com/oneir0mancer/stable-diffusion-diffusers-colab-ui.git StableDiffusionUi\n",
        "!git clone https://huggingface.co/embed/negative /content/embeddings/negative\n",
        "!git clone https://huggingface.co/embed/lora /content/Lora/positive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating model pipeline"
      ],
      "metadata": {
        "id": "QRvNp3ElcaA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<details>\n",
        "<summary><b>Description</b><br>TLDR: use dropdown or just paste</summary>\n",
        "\n",
        "---\n",
        "\n",
        "You can just choose a model from a dropdown of popular models, which will also give you a link to a model page on [huggingface](https://huggingface.co) and any trigger words you need to use in the prompt.\n",
        "\n",
        "Alternatively, you can paste a model_id, url, or local path for any model from huggingface:\n",
        "\n",
        "* **model_id** looks like this: `gsdf/Counterfeit-V2.5`.\n",
        "<br>You can use it for any *proper* diffusers model in huggingface, i.e. ones that have a lot of folders in their **Files**, and a file called **model_index.json**\n",
        "<br> `A1111 format` toggle should be **<font color= 'red'>off</font>**.\n",
        "\n",
        "* **url** may look like this:\n",
        "```\n",
        "https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix/AbyssOrangeMix.safetensors\n",
        "```\n",
        "Use it when the model is in Automatic1111 format, as in, just a single file.\n",
        "<br> `A1111 format` toggle should be **<font color= 'green'>on</font>**.\n",
        "\n",
        "* **local path** is just a path to a model folder (if diffusers format) or model file (if A1111 format).\n",
        "<br>Set toggle accordingly.\n",
        "\n",
        "Urls from civit.ai (the ones you get from clicking \"Download\") may also work, I'm not sure.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "dVlvLpShS9eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Where to find urls</summary>\n",
        "\n",
        "A good place to find model urls is  [camenduru colabs repo](https://https://github.com/camenduru/stable-diffusion-webui-colab), just look for a line starting with `!aria2c ...`\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "dviyU3E6jK01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Render model choice UI\n",
        "output_index = 0\n",
        "cache = None\n",
        "\n",
        "from StableDiffusionUi.ColabUI.HugginfaceModelIndex import HugginfaceModelIndex\n",
        "\n",
        "model_index = HugginfaceModelIndex(\"/content/StableDiffusionUi/model_index.json\")\n",
        "model_index.render()"
      ],
      "metadata": {
        "id": "k_TR5dUwznN9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load chosen model\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "model_id, from_ckpt = model_index.get_model_id()\n",
        "loader_func = StableDiffusionPipeline.from_single_file if from_ckpt else StableDiffusionPipeline.from_pretrained\n",
        "\n",
        "pipe = loader_func(model_id,\n",
        "                   custom_pipeline=\"lpw_stable_diffusion\",\n",
        "                   torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.safety_checker = None\n",
        "pipe.enable_xformers_memory_efficient_attention()"
      ],
      "metadata": {
        "id": "IBdm3HvI02Yo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Technical detail</summary>\n",
        "\n",
        "I use [this](https://github.com/huggingface/diffusers/tree/main/examples/community#long-prompt-weighting-stable-diffusion) custom pipeline which doesn't have a token length limit and allows to use weights in prompt.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "pAJzkJWpeOxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional stuff:"
      ],
      "metadata": {
        "id": "CWqvp4vYeM_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Change sampler\n",
        "from diffusers import EulerAncestralDiscreteScheduler, DPMSolverMultistepScheduler, UniPCMultistepScheduler\n",
        "\n",
        "choose_sampler = \"UniPC\" #@param [\"Euler A\", \"DPM++\", \"DPM++ Karras\", \"UniPC\"]\n",
        "\n",
        "if choose_sampler == \"Euler A\":\n",
        "    solver = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "elif choose_sampler == \"DPM++\":\n",
        "    solver = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "elif choose_sampler == \"DPM++ Karras\":\n",
        "    solver = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "    solver.use_karras_sigmas = True\n",
        "elif choose_sampler == \"UniPC\":\n",
        "    solver = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "pipe.scheduler = solver\n",
        "print(f\"Sampler '{choose_sampler}' chosen\")"
      ],
      "metadata": {
        "id": "9i7ZbasUpTh7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VAE\n",
        "\n",
        "Most models come with their own VAE, but changing it may improve generation results. Especially if you get a lot of artifacts or just black images.\n",
        "\n",
        "You can load VAE from any [huggingface](https://huggingface.co) repository, just paste their **model_id** and subfolder (usually just \"vae\")."
      ],
      "metadata": {
        "id": "hEwlf_SQXCyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##(Optional) Load VAE\n",
        "\n",
        "from diffusers import AutoencoderKL\n",
        "\n",
        "vae_id_or_path = \"waifu-diffusion/wd-1-5-beta2\"  #@param {type: \"string\"}\n",
        "vae_subfolder = \"vae\"    #@param {type: \"string\"}\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(vae_id_or_path, subfolder=vae_subfolder, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.vae = vae"
      ],
      "metadata": {
        "id": "8jKsuQ9E5eCK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Textual inversions"
      ],
      "metadata": {
        "id": "mY0xKEW2lgmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can load any textual inversions using\n",
        "```\n",
        "pipe.load_textual_inversion(\"path/to/dir\", weight_name=\"filename.pt\")\n",
        "```\n",
        "To use them, you need to add theit token to a prompt like this `<filename>`.\n",
        "\n",
        "Note that you need to reload textual inversions every time you switch VAE."
      ],
      "metadata": {
        "id": "VDQSRzWg5OKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###(Optional) Load textual inversions\n",
        "#@markdown Load every embedding with **.pt** extension from **embeddings** folder.\n",
        "\n",
        "import os\n",
        "\n",
        "for path, subdirs, files in os.walk(\"/content/embeddings/\"):\n",
        "    for name in files:\n",
        "        try:\n",
        "            if os.path.splitext(name)[1] != \".pt\": continue\n",
        "            pipe.load_textual_inversion(path, weight_name=name)\n",
        "            print(path, name)\n",
        "        except: pass"
      ],
      "metadata": {
        "id": "VVU2Rjpb085a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LoRA"
      ],
      "metadata": {
        "id": "lYurBnHCbZ3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lora support is somewhat limited, and they make generation slower. I'm kinda lazy to write something that will make it more convenient, so for now we can just use code examples from [here](https://huggingface.co/docs/diffusers/main/en/training/lora#supporting-a1111-themed-lora-checkpoints-from-diffusers).\n",
        "\n",
        "First, we can download loras, i.e. from Civitai like this (you can \"Copy link\" from download button):\n",
        "```python\n",
        "!wget https://civitai.com/api/download/models/15603 --content-disposition\n",
        "```\n",
        "To apply lora, run\n",
        "```python\n",
        "pipe.load_lora_weights(\"path/to/folder\", weight_name=\"lora_filename.safetensors\")\n",
        "```\n",
        "Then you can fuse lora, which will merge it's weights to model weights and make it faster. It also seem to be the only way to set lora scale:\n",
        "```python\n",
        "pipe.fuse_lora(lora_scale=0.5)\n",
        "```\n",
        "To unfuse lora (you need to use the same scale):\n",
        "```python\n",
        "pipe.unfuse_lora(lora_scale=0.5)\n",
        "```"
      ],
      "metadata": {
        "id": "3ERA2tR6bf-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating images"
      ],
      "metadata": {
        "id": "hLmzZmRIZMpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Render UI\n",
        "#@markdown You don't need to run this cell again unless you want to change these settings\n",
        "save_images = True #@param {type:\"boolean\"}\n",
        "display_previewes = True    #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "from  StableDiffusionUi.ColabUI.DiffusionPipelineUI import DiffusionPipelineUI\n",
        "\n",
        "ui = DiffusionPipelineUI()\n",
        "if (cache is not None):\n",
        "    ui.load_cache(cache)\n",
        "\n",
        "ui.render()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oFruEVcl4ODt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color='red'>Run</font> this cell to generate images\n",
        "cache = ui.get_dict_to_cache()\n",
        "\n",
        "results = ui.generate(pipe)\n",
        "if save_images:\n",
        "    for i, image in enumerate(results.images):\n",
        "        path = f\"outputs/txt2img/{output_index:05}.png\"\n",
        "        ui.save_image_with_metadata(image, path, f\"Batch: {i}\\n\")\n",
        "        print(path)\n",
        "        output_index += 1\n",
        "\n",
        "if display_previewes:\n",
        "    ui.display_image_previews(results.images)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y43YLjY7F7NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utils"
      ],
      "metadata": {
        "id": "gthYZKknKsw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## Image viewer\n",
        "#@markdown Run this cell to view last results in full size\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "slider = widgets.IntSlider(max=len(results.images)-1)\n",
        "\n",
        "def handler(change):\n",
        "    slider.max = len(results.images)-1\n",
        "    if change.new > slider.max: change.new = slider.max\n",
        "    clear_output(wait=True)\n",
        "    display(slider, results.images[change.new])\n",
        "\n",
        "slider.observe(handler, names='value')\n",
        "\n",
        "display(slider, results.images[slider.value])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9vn2Z5tNIAiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting models from ckpt\n",
        "You shouldn't really need this, because diffusers now support loading from A1111 format.\n",
        "\n",
        "But if you want, you can download a model and convert it to diffusers format."
      ],
      "metadata": {
        "id": "kRUTJXoBc4tG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: A good place to find model urls is  [camenduru colabs repo](https://https://github.com/camenduru/stable-diffusion-webui-colab), just look for a line starting with `!aria2c ...`\n"
      ],
      "metadata": {
        "id": "av9urfOqi7Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Download ckpt file\n",
        "#@markdown Download ckpt/safetensors file from huggingface url.\n",
        "\n",
        "#@markdown ---\n",
        "import os\n",
        "\n",
        "url = \"https://huggingface.co/mekabu/MagicalMix_v2/resolve/main/MagicalMix_v2.safetensors\" #@param {type:\"string\"}\n",
        "ckpt_dump_folder = \"/content/models_sd/\"    #@param {type:\"string\"}\n",
        "model_name = url.split('/')[-1]\n",
        "\n",
        "bashCommand = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url} -d {ckpt_dump_folder} -o {model_name}\"\n",
        "os.system(bashCommand)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "w1JZPBKId6Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##(Optional) Or just upload file\n",
        "from google.colab import files\n",
        "f = files.upload()\n",
        "\n",
        "ckpt_dump_folder = \"/content/\"\n",
        "for key in f.keys():\n",
        "    model_name = key\n",
        "    break"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dOn6tR_4eJ8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Run conversion script\n",
        "#@markdown Paste a path to where you want this script to cache a model into `dump_path`.\n",
        "\n",
        "#@markdown Keep `override_path` empty unless you uploaded your file to some custom directory.\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from diffusers.pipelines.stable_diffusion.convert_from_ckpt import download_from_original_stable_diffusion_ckpt\n",
        "\n",
        "from_safetensors = True #@param {type:\"boolean\"}\n",
        "override_path = \"\" #@param {type:\"string\"}\n",
        "if override_path != \"\":\n",
        "    checkpoint_path = override_path\n",
        "else:\n",
        "    checkpoint_path = os.path.join(ckpt_dump_folder, model_name)\n",
        "\n",
        "pipe = download_from_original_stable_diffusion_ckpt(\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        original_config_file = \"/content/v1-inference.yaml\",\n",
        "        from_safetensors=from_safetensors,\n",
        "    )\n",
        "\n",
        "dump_path=\"models/ModelName/\" #@param {type:\"string\"}\n",
        "pipe.save_pretrained(dump_path, safe_serialization=from_safetensors)\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.safety_checker = None\n",
        "pipe.to(torch_dtype=torch.float16)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N1GOOJrej6tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting VAE"
      ],
      "metadata": {
        "id": "ii9UDlWQnIhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Download vae file\n",
        "#@markdown Basically, the same thing as model files\n",
        "\n",
        "#@markdown ---\n",
        "import os\n",
        "\n",
        "url = \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\" #@param {type:\"string\"}\n",
        "ckpt_dump_folder = \"/content/models_sd/\"    #@param {type:\"string\"}\n",
        "model_name = url.split('/')[-1]\n",
        "\n",
        "bashCommand = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url} -d {ckpt_dump_folder} -o {model_name}\"\n",
        "os.system(bashCommand)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "916cyCYPnNVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Paste a path to where you want this script to cache a vae into `dump_path`.\n",
        "from_safetensors = False #@param {type:\"boolean\"}\n",
        "dump_path=\"vae/VaeName/\" #@param {type:\"string\"}\n",
        "\n",
        "checkpoint_path = os.path.join(ckpt_dump_folder, model_name)\n",
        "bashCommand = f\"python /content/StableDiffusionUi/scripts/convert_vae_pt_to_diffusers.py --vae_pt_path {checkpoint_path} --dump_path {dump_path}\"\n",
        "if from_safetensors:\n",
        "    bashCommand += \" --from_safetensors\"\n",
        "os.system(bashCommand)"
      ],
      "metadata": {
        "id": "dWC8UpJ3m8Fa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}