{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oneir0mancer/stable-diffusion-diffusers-colab-ui/blob/main/sd_diffusers_colab_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x-z4MGy9rz9I"
      },
      "outputs": [],
      "source": [
        "#@title #Install dependencies\n",
        "!git clone https://github.com/oneir0mancer/stable-diffusion-diffusers-colab-ui.git StableDiffusionUi\n",
        "\n",
        "!pip install -r StableDiffusionUi/requirements.txt\n",
        "!wget https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
        "\n",
        "!mkdir -p outputs/{txt2img,img2img}\n",
        "!git clone https://huggingface.co/embed/negative /content/embeddings/negative\n",
        "!git clone https://huggingface.co/embed/lora /content/Lora/positive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRvNp3ElcaA3"
      },
      "source": [
        "# Creating model pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVlvLpShS9eo"
      },
      "source": [
        "\n",
        "<details>\n",
        "<summary><b>Description</b><br>TLDR: use dropdown or just paste stuff</summary>\n",
        "\n",
        "---\n",
        "\n",
        "You can just choose a model from a dropdown of popular models, which will also give you a link to a model page on [huggingface](https://huggingface.co) and any trigger words you need to use in the prompt.\n",
        "\n",
        "Alternatively, you can paste a **model_id**, **url**, or **local path** for any model from huggingface:\n",
        "\n",
        "* **model_id** looks like this: `gsdf/Counterfeit-V2.5`.\n",
        "<br>You can use it for any *proper* diffusers model in huggingface, i.e. ones that have a lot of folders in their **Files**, and a file called **model_index.json**\n",
        "<br> `ðŸ”² A1111 format` toggle should be **<font color= 'red'>off</font>**.\n",
        "\n",
        "* **url** from HuggingFace may look like this:\n",
        "```\n",
        "https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix/AbyssOrangeMix.safetensors\n",
        "```\n",
        "Use it when the model is in Automatic1111 format (as in, just a single file).\n",
        "<br> `âœ… A1111 format` toggle should be **<font color= 'green'>on</font>**.\n",
        "\n",
        "* **url** from CivitAI should look like this:\n",
        "```\n",
        "https://civitai.com/api/download/models/XXXXXX\n",
        "```\n",
        "(the link you get from \"Download\" button)\n",
        "<br> `âœ… A1111 format` toggle should be **<font color= 'green'>on</font>**.\n",
        "\n",
        "* **local path** is just a path to a model folder (if diffusers format) or model file (if A1111 format).\n",
        "<br>Set toggle accordingly.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dviyU3E6jK01"
      },
      "source": [
        "<details>\n",
        "<summary>Where to find urls</summary>\n",
        "\n",
        "A good place to find model urls is  [camenduru colabs repo](https://https://github.com/camenduru/stable-diffusion-webui-colab), just look for a line starting with `!aria2c ...`\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k_TR5dUwznN9"
      },
      "outputs": [],
      "source": [
        "#@title Render model choice UI\n",
        "\n",
        "from StableDiffusionUi.ColabUI.ColabWrapper import ColabWrapper\n",
        "\n",
        "colab = ColabWrapper(\"outputs/txt2img\")\n",
        "colab.render_model_index(\"/content/StableDiffusionUi/model_index.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IBdm3HvI02Yo"
      },
      "outputs": [],
      "source": [
        "#@title Load chosen SD model\n",
        "\n",
        "#TODO we have to use this until LPW properly supports clip skip\n",
        "from StableDiffusionUi.lpw_stable_diffusion import StableDiffusionLongPromptWeightingPipeline\n",
        "colab.load_model(StableDiffusionLongPromptWeightingPipeline, custom_pipeline=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (*Optional*) Run this instead to load SDXL model\n",
        "#@markdown You probably won't be able to load model in A1111 format because there is not enought RAM for conversion\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "\n",
        "colab.load_model(StableDiffusionXLPipeline, custom_pipeline=\"lpw_stable_diffusion_xl\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AG4ChqboGDO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAJzkJWpeOxk"
      },
      "source": [
        "<details>\n",
        "<summary>Prompting detail</summary>\n",
        "\n",
        "I use [this](https://github.com/huggingface/diffusers/tree/main/examples/community#long-prompt-weighting-stable-diffusion) custom pipeline which doesn't have a token length limit and allows to use weights in prompt.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLmzZmRIZMpC"
      },
      "source": [
        "# Generating images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oFruEVcl4ODt"
      },
      "outputs": [],
      "source": [
        "#@title Render UI\n",
        "#@markdown ---\n",
        "from  StableDiffusionUi.ColabUI.DiffusionPipelineUI import DiffusionPipelineUI\n",
        "\n",
        "ui = DiffusionPipelineUI()\n",
        "colab.render_generation_ui(ui)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y43YLjY7F7NI"
      },
      "outputs": [],
      "source": [
        "#@title <font color='red'>Run</font> this cell to generate images\n",
        "colab.generate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gthYZKknKsw7"
      },
      "source": [
        "#Utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Img2img refiner UI\n",
        "# We have to load custom pipeline ourselves because you can't pass it when reusing pipe components\n",
        "from diffusers.utils import get_class_from_dynamic_module\n",
        "Interface = get_class_from_dynamic_module(colab.custom_pipeline, module_file=f\"{colab.custom_pipeline}.py\")\n",
        "colab.render_refiner_ui(Interface)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d9oniqPLdZ4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color='red'>Run</font> img2img\n",
        "colab.refiner_generate(output_dir=\"outputs/img2img\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zyk-JX0OeKvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conversion"
      ],
      "metadata": {
        "id": "mHUsrD28erB4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRUTJXoBc4tG"
      },
      "source": [
        "## Converting models from ckpt\n",
        "You shouldn't really need this, because diffusers now support loading from A1111 format.\n",
        "\n",
        "But if you want, you can download a model and convert it to diffusers format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av9urfOqi7Ak"
      },
      "source": [
        "NOTE: A good place to find model urls is  [camenduru colabs repo](https://https://github.com/camenduru/stable-diffusion-webui-colab), just look for a line starting with `!aria2c ...`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w1JZPBKId6Zv"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Download ckpt file\n",
        "#@markdown Download ckpt/safetensors file from huggingface url.\n",
        "\n",
        "#@markdown ---\n",
        "import os\n",
        "\n",
        "url = \"https://huggingface.co/mekabu/MagicalMix_v2/resolve/main/MagicalMix_v2.safetensors\" #@param {type:\"string\"}\n",
        "ckpt_dump_folder = \"/content/models_sd/\"    #@param {type:\"string\"}\n",
        "model_name = url.split('/')[-1]\n",
        "\n",
        "os.system(f\"mkdir -p {ckpt_dump_folder}\")\n",
        "bashCommand = f\"wget {url} -P {ckpt_dump_folder} --content-disposition\"\n",
        "os.system(bashCommand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dOn6tR_4eJ8k"
      },
      "outputs": [],
      "source": [
        "#@markdown ##(Optional) Or just upload file\n",
        "from google.colab import files\n",
        "f = files.upload()\n",
        "\n",
        "ckpt_dump_folder = \"/content/\"\n",
        "for key in f.keys():\n",
        "    model_name = key\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N1GOOJrej6tW"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Run conversion script\n",
        "#@markdown Paste a path to where you want this script to cache a model into `dump_path`.\n",
        "\n",
        "#@markdown Keep `override_path` empty unless you uploaded your file to some custom directory.\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from diffusers.pipelines.stable_diffusion.convert_from_ckpt import download_from_original_stable_diffusion_ckpt\n",
        "\n",
        "from_safetensors = True #@param {type:\"boolean\"}\n",
        "override_path = \"\" #@param {type:\"string\"}\n",
        "if override_path != \"\":\n",
        "    checkpoint_path = override_path\n",
        "else:\n",
        "    checkpoint_path = os.path.join(ckpt_dump_folder, model_name)\n",
        "\n",
        "pipe = download_from_original_stable_diffusion_ckpt(\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        original_config_file = \"/content/v1-inference.yaml\",\n",
        "        from_safetensors=from_safetensors,\n",
        "    )\n",
        "\n",
        "dump_path=\"models/ModelName/\" #@param {type:\"string\"}\n",
        "pipe.save_pretrained(dump_path, safe_serialization=from_safetensors)\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.safety_checker = None\n",
        "pipe.to(torch_dtype=torch.float16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii9UDlWQnIhg"
      },
      "source": [
        "## Converting VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "916cyCYPnNVt"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Download vae file\n",
        "#@markdown Basically, the same thing as model files\n",
        "\n",
        "#@markdown ---\n",
        "import os\n",
        "\n",
        "url = \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\" #@param {type:\"string\"}\n",
        "ckpt_dump_folder = \"/content/models_sd/\"    #@param {type:\"string\"}\n",
        "model_name = url.split('/')[-1]\n",
        "\n",
        "os.system(f\"mkdir -p {ckpt_dump_folder}\")\n",
        "bashCommand = f\"wget {url} -P {ckpt_dump_folder} --content-disposition\"\n",
        "os.system(bashCommand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dWC8UpJ3m8Fa"
      },
      "outputs": [],
      "source": [
        "#@markdown Paste a path to where you want this script to cache a vae into `dump_path`.\n",
        "from_safetensors = False #@param {type:\"boolean\"}\n",
        "dump_path=\"vae/VaeName/\" #@param {type:\"string\"}\n",
        "\n",
        "checkpoint_path = os.path.join(ckpt_dump_folder, model_name)\n",
        "bashCommand = f\"python /content/StableDiffusionUi/scripts/convert_vae_pt_to_diffusers.py --vae_pt_path {checkpoint_path} --dump_path {dump_path}\"\n",
        "if from_safetensors:\n",
        "    bashCommand += \" --from_safetensors\"\n",
        "os.system(bashCommand)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color='red'>Flush</font> model\n"
      ],
      "metadata": {
        "id": "33zsLV1d0CKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "del colab.pipe\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "aWqoBQP60OyY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mHUsrD28erB4",
        "kRUTJXoBc4tG",
        "ii9UDlWQnIhg",
        "33zsLV1d0CKE"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}