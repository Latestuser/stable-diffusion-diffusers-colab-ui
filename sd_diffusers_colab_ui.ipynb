{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM86nXsbxx9kuQo4Duh1Hkq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oneir0mancer/stable-diffusion-diffusers-colab-ui/blob/main/sd_diffusers_colab_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "c7VG6GVTS0Al"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-z4MGy9rz9I"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade diffusers accelerate transformers xformers safetensors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/embed/negative /content/embeddings/negative\n",
        "!git clone https://huggingface.co/embed/lora /content/Lora/positive"
      ],
      "metadata": {
        "id": "H-XcdgK8yboS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "def dummy(images, **kwargs):\n",
        "    return images, False\n",
        "\n",
        "output_index = 0"
      ],
      "metadata": {
        "id": "DG4psBfYsUp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating model pipeline\n",
        "You can use **model_id** from [huggingface](https://huggingface.co), if the model is in diffusers format. Just check **Files** and see if there is a `model_index.json`.\n",
        "\n",
        "Or you can download weights, and use `/content/path/to/model/dir/`.\n",
        "\n",
        "Weights in Automatic111 format (**.ckpt** or **.safetensors** but without model_index.json) need to be converted using scripts."
      ],
      "metadata": {
        "id": "dVlvLpShS9eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create pipeline\n",
        "model_id_or_path = \"runwayml/stable-diffusion-v1-5\"  #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(model_id_or_path).to(\"cuda\")\n",
        "pipe.safety_checker = dummy"
      ],
      "metadata": {
        "id": "IBdm3HvI02Yo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same rules apply for VAE. You can load it from some repository on [huggingface](https://huggingface.co) using its **model_id** and subfolder. \n",
        "\n",
        "Or you can load it in Automatic111 format and convert using scripts."
      ],
      "metadata": {
        "id": "hEwlf_SQXCyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Load VAE\n",
        "\n",
        "from diffusers import AutoencoderKL\n",
        "\n",
        "vae_id_or_path = \"runwayml/stable-diffusion-v1-5\"  #@param {type: \"string\"}\n",
        "vae_subfolder = \"vae\"    #@param {type: \"string\"}\n",
        "vae = AutoencoderKL.from_pretrained(\"vae_id_or_path\", subfolder=vae_subfolder).to(\"cuda\")\n",
        "pipe.vae = vae"
      ],
      "metadata": {
        "id": "8jKsuQ9E5eCK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Load textual inversions\n",
        "#@markdown This is work in progress. Load every embedding with **.pt** extension from **embeddings** folder.\n",
        "\n",
        "import os\n",
        "\n",
        "for path, subdirs, files in os.walk(\"/content/embeddings/\"):\n",
        "    for name in files:\n",
        "        if os.path.splitext(name)[1] != \".pt\": continue\n",
        "        pipe.load_textual_inversion(path, weight_name=name)\n",
        "        print(path, name)"
      ],
      "metadata": {
        "id": "VVU2Rjpb085a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can load any other textual inversions using \n",
        "```\n",
        "pipe.load_textual_inversion(\"path/to/dir\", weight_name=\"filename.pt\")\n",
        "```\n",
        "To use them, you need to add theit token to a prompt like this `<filename>`.\n",
        "\n",
        "Note, that it seems that if you change VAE after loading textual inversions, using them will degrade generated images."
      ],
      "metadata": {
        "id": "inFUmCzUcfBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating images"
      ],
      "metadata": {
        "id": "hLmzZmRIZMpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to generate images\n",
        "prompt = \"best quality, 1girl, illustration\"  #@param {type: \"string\"}\n",
        "negative_prompt = \"EasyNegative, by <bad-artist-anime>, worst quality, awful quality\"   #@param {type: \"string\"}\n",
        "\n",
        "width = 512 #@param {type:\"integer\"}\n",
        "height = 768    #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "steps = 20  #@param {type: \"slider\", min: 1, max: 100}\n",
        "CFG = 7 #@param {type: \"slider\", min: 1, max: 20}\n",
        "seed = -1   #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "if seed < 0: generator = torch.Generator()\n",
        "else: generator = torch.manual_seed(seed)\n",
        "\n",
        "results = pipe(prompt, negative_prompt=negative_prompt, num_inference_steps=steps, guidance_scale=CFG, \n",
        "               generator=generator, height=768, width=512)\n",
        "\n",
        "results.images[0]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fqUSaM3WteZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save image\n",
        "results.images[0].save(f\"{output_index:05}.png\")\n",
        "output_index += 1"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CkH55gyGe6TW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}