{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNFYNarR+Yxkf6+cg7DFr2q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oneir0mancer/stable-diffusion-diffusers-colab-ui/blob/main/sd_diffusers_colab_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "c7VG6GVTS0Al"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-z4MGy9rz9I"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade diffusers accelerate transformers xformers safetensors\n",
        "!mkdir -p outputs/{txt2img,img2img}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/oneir0mancer/stable-diffusion-diffusers-colab-ui.git StableDiffusionUi\n",
        "!git clone https://huggingface.co/embed/negative /content/embeddings/negative\n",
        "!git clone https://huggingface.co/embed/lora /content/Lora/positive"
      ],
      "metadata": {
        "id": "H-XcdgK8yboS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "output_index = 0\n",
        "generator = torch.Generator()"
      ],
      "metadata": {
        "id": "DG4psBfYsUp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating model pipeline\n",
        "You can use most from [huggingface](https://huggingface.co). Just make sure they are in diffusers format, check their **Files** and see if there is a `model_index.json`.\n",
        "\n",
        "I made a simple index wih popular models, so you can just render UI and choose a model from dropdown. Some models require trigger word in the prompt.\n",
        "\n",
        "For weights in Automatic111 format (**.ckpt** or **.safetensors** but without model_index.json), you'll need to download them and [convert using scripts](#scrollTo=kRUTJXoBc4tG&line=4&uniqifier=1)."
      ],
      "metadata": {
        "id": "dVlvLpShS9eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Render model choice UI\n",
        "from StableDiffusionUi.ColabUI.HugginfaceModelIndex import HugginfaceModelIndex\n",
        "\n",
        "model_index = HugginfaceModelIndex(\"/content/StableDiffusionUi/model_index.json\")\n",
        "model_index.render()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "k_TR5dUwznN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load chosen model\n",
        "#@markdown Alternatively you can just paste huggingface model_id or path to model folder here:\n",
        "\n",
        "path_to_model = \"\"  #@param {type: \"string\"}\n",
        "\n",
        "if path_to_model != \"\": model_id = path_to_model\n",
        "else: model_id = model_index.get_model_id()\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.safety_checker = None"
      ],
      "metadata": {
        "id": "IBdm3HvI02Yo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Change sampler \n",
        "from diffusers import EulerAncestralDiscreteScheduler, DPMSolverMultistepScheduler, UniPCMultistepScheduler\n",
        "\n",
        "choose_sampler = \"Euler A\" #@param [\"Euler A\", \"DPM++\", \"DPM++ Karras\", \"UniPC\"]\n",
        "\n",
        "if choose_sampler == \"Euler A\":\n",
        "    solver = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "elif choose_sampler == \"DPM++\":\n",
        "    solver = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "elif choose_sampler == \"DPM++ Karras\":\n",
        "    solver = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "    solver.use_karras_sigmas = True\n",
        "elif choose_sampler == \"UniPC\":\n",
        "    solver = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "pipe.scheduler = solver\n",
        "print(f\"Sampler '{choose_sampler}' chosen\")"
      ],
      "metadata": {
        "id": "9i7ZbasUpTh7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE\n",
        "\n",
        "Models loaded from huggingface should have proper VAE. But you also can load VAE from any other repository from [huggingface](https://huggingface.co), just paste their **model_id** and subfolder (usually just \"vae\"). \n",
        "\n",
        "Or you can load it in Automatic111 format and convert using scripts."
      ],
      "metadata": {
        "id": "hEwlf_SQXCyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Load VAE\n",
        "\n",
        "from diffusers import AutoencoderKL\n",
        "\n",
        "vae_id_or_path = \"runwayml/stable-diffusion-v1-5\"  #@param {type: \"string\"}\n",
        "vae_subfolder = \"vae\"    #@param {type: \"string\"}\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(vae_id_or_path, subfolder=vae_subfolder, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.vae = vae"
      ],
      "metadata": {
        "id": "8jKsuQ9E5eCK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Textual inversions and LoRAs\n",
        "This is work in progress. \n",
        "\n",
        "You can load any textual inversions using \n",
        "```\n",
        "pipe.load_textual_inversion(\"path/to/dir\", weight_name=\"filename.pt\")\n",
        "```\n",
        "To use them, you need to add theit token to a prompt like this `<filename>`.\n",
        "\n",
        "Note, that it seems that if you change VAE after loading textual inversions, using them will degrade generated images."
      ],
      "metadata": {
        "id": "VDQSRzWg5OKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Load textual inversions\n",
        "#@markdown Load every embedding with **.pt** extension from **embeddings** folder.\n",
        "\n",
        "import os\n",
        "\n",
        "for path, subdirs, files in os.walk(\"/content/embeddings/\"):\n",
        "    for name in files:\n",
        "        try:\n",
        "            if os.path.splitext(name)[1] != \".pt\": continue\n",
        "            pipe.load_textual_inversion(path, weight_name=name)\n",
        "            print(path, name)\n",
        "        except: pass"
      ],
      "metadata": {
        "id": "VVU2Rjpb085a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating images"
      ],
      "metadata": {
        "id": "hLmzZmRIZMpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Render UI\n",
        "#@markdown You don't need to run this cell again unless you want to change these settings\n",
        "save_images = True #@param {type:\"boolean\"}\n",
        "display_previewes = True    #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "from  StableDiffusionUi.ColabUI.DiffusionPipelineUI import DiffusionPipelineUI\n",
        "\n",
        "ui = DiffusionPipelineUI()\n",
        "ui.render()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oFruEVcl4ODt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to generate images\n",
        "results = ui.generate(pipe, generator)\n",
        "\n",
        "if display_previewes:\n",
        "    ui.display_image_previews(results.images)\n",
        "\n",
        "if save_images:\n",
        "    for image in results.images:\n",
        "        image.save(f\"outputs/txt2img/{output_index:05}.png\")\n",
        "        print(f\"outputs/txt2img/{output_index:05}.png\")\n",
        "        output_index += 1"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y43YLjY7F7NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utils"
      ],
      "metadata": {
        "id": "gthYZKknKsw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image viewer\n",
        "#@markdown Run this cell to view last results in full size\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "slider = widgets.IntSlider(max=len(results.images)-1)\n",
        "\n",
        "def handler(change):\n",
        "    slider.max = len(results.images)-1\n",
        "    if change.new > slider.max: change.new = slider.max\n",
        "    clear_output(wait=True)\n",
        "    display(slider, results.images[change.new])\n",
        "\n",
        "slider.observe(handler, names='value')\n",
        "\n",
        "display(slider, results.images[slider.value])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9vn2Z5tNIAiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting models from ckpt\n",
        "A lot of models from huggingface/civitai use ckpt/safetensors format, that is not supported by diffusers pipelines.\n",
        "\n",
        "So we want to download them, and then convert to diffusers format using conversion scripts. That will allow us to load them, using [this cell](#scrollTo=IBdm3HvI02Yo).\n",
        "\n",
        "If after conversion results look bad, try changing sampler."
      ],
      "metadata": {
        "id": "kRUTJXoBc4tG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "#@markdown You may need to restart runtime after that: `Runtime -> Restart Runtime`\n",
        "!wget https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
        "!apt -y install -qq aria2\n",
        "!pip install pytorch-lightning\n",
        "!pip install omegaconf"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OUqWojdfc_P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Download ckpt file\n",
        "#@markdown Download ckpt/safetensors file from huggingface url. \n",
        "\n",
        "#@markdown A good place to find these urls is  [camenduru colabs repo](https://https://github.com/camenduru/stable-diffusion-webui-colab), just look for a line starting with `!aria2c ...`\n",
        "\n",
        "#@markdown ---\n",
        "import os\n",
        "\n",
        "url = \"https://huggingface.co/mekabu/MagicalMix_v2/resolve/main/MagicalMix_v2.safetensors\" #@param {type:\"string\"}\n",
        "ckpt_dump_folder = \"/content/models_sd/\"    #@param {type:\"string\"}\n",
        "model_name = url.split('/')[-1]\n",
        "\n",
        "bashCommand = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url} -d {ckpt_dump_folder} -o {model_name}\"\n",
        "os.system(bashCommand)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "w1JZPBKId6Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Or just upload file\n",
        "from google.colab import files\n",
        "f = files.upload()\n",
        "\n",
        "ckpt_dump_folder = \"/content/\"\n",
        "for key in f.keys():\n",
        "    model_name = key\n",
        "    break"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dOn6tR_4eJ8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run conversion script\n",
        "#@markdown Paste a path to where you want this script to cache a model into `dump_path`.\n",
        "\n",
        "#@markdown Keep `override_path` empty unless you uploaded your file to some custom directory.\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from diffusers.pipelines.stable_diffusion.convert_from_ckpt import download_from_original_stable_diffusion_ckpt\n",
        "\n",
        "from_safetensors = True #@param {type:\"boolean\"}\n",
        "override_path = \"\" #@param {type:\"string\"}\n",
        "if override_path != \"\":\n",
        "    checkpoint_path = override_path\n",
        "else:\n",
        "    checkpoint_path = os.path.join(ckpt_dump_folder, model_name)\n",
        "\n",
        "pipe = download_from_original_stable_diffusion_ckpt(\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        original_config_file = \"/content/v1-inference.yaml\",\n",
        "        from_safetensors=from_safetensors,\n",
        "    )\n",
        "\n",
        "dump_path=\"models/ModelName/\" #@param {type:\"string\"}\n",
        "pipe.save_pretrained(dump_path, safe_serialization=from_safetensors)\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.safety_checker = None\n",
        "pipe.to(torch_dtype=torch.float16)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N1GOOJrej6tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Converting VAE\n"
      ],
      "metadata": {
        "id": "ii9UDlWQnIhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Download vae file\n",
        "#@markdown Basically, the same thing as model files\n",
        "\n",
        "#@markdown ---\n",
        "import os\n",
        "\n",
        "url = \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\" #@param {type:\"string\"}\n",
        "ckpt_dump_folder = \"/content/models_sd/\"    #@param {type:\"string\"}\n",
        "model_name = url.split('/')[-1]\n",
        "\n",
        "bashCommand = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url} -d {ckpt_dump_folder} -o {model_name}\"\n",
        "os.system(bashCommand)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "916cyCYPnNVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Paste a path to where you want this script to cache a vae into `dump_path`.\n",
        "from_safetensors = True #@param {type:\"boolean\"}\n",
        "dump_path=\"vae/VaeName/\" #@param {type:\"string\"}\n",
        "\n",
        "checkpoint_path = os.path.join(ckpt_dump_folder, model_name)\n",
        "bashCommand = f\"python /content/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path {checkpoint_path} --dump_path={dump_path}\"\n",
        "if from_safetensors:\n",
        "    bashCommand += \" --from_safetensors\"\n",
        "os.system(bashCommand)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dWC8UpJ3m8Fa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}