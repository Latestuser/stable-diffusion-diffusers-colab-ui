{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "c7VG6GVTS0Al"
      ],
      "authorship_tag": "ABX9TyMYw86volO4N7z97rfZ/I9Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oneir0mancer/stable-diffusion-diffusers-colab-ui/blob/main/sd_diffusers_colab_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "c7VG6GVTS0Al"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-z4MGy9rz9I"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade diffusers accelerate transformers xformers safetensors\n",
        "!mkdir -p outputs/{txt2img,img2img}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/oneir0mancer/stable-diffusion-diffusers-colab-ui.git StableDiffusionUi\n",
        "!git clone https://huggingface.co/embed/negative /content/embeddings/negative\n",
        "!git clone https://huggingface.co/embed/lora /content/Lora/positive"
      ],
      "metadata": {
        "id": "H-XcdgK8yboS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "output_index = 0\n",
        "generator = torch.Generator()"
      ],
      "metadata": {
        "id": "DG4psBfYsUp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating model pipeline\n",
        "You can use most from [huggingface](https://huggingface.co). Just make sure they are in diffusers format, check their **Files** and see if there is a `model_index.json`.\n",
        "\n",
        "I made a simple index wih popular models, so you can just render UI and choose a model from dropdown. Some models require trigger word in the prompt.\n",
        "\n",
        "For weights in Automatic111 format (**.ckpt** or **.safetensors** but without model_index.json), you'll need to download them and convert using scripts (WIP)."
      ],
      "metadata": {
        "id": "dVlvLpShS9eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Render model choice UI\n",
        "from StableDiffusionUi.ColabUI.HugginfaceModelIndex import HugginfaceModelIndex\n",
        "\n",
        "model_index = HugginfaceModelIndex(\"/content/StableDiffusionUi/model_index.json\")\n",
        "model_index.render()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "k_TR5dUwznN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load chosen model\n",
        "#@markdown Alternatively you can just paste huggingface model_id or path to model folder here:\n",
        "\n",
        "path_to_model = \"\"  #@param {type: \"string\"}\n",
        "\n",
        "if path_to_model != \"\": model_id = path_to_model\n",
        "else: model_id = model_index.get_model_id()\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.safety_checker = None"
      ],
      "metadata": {
        "id": "IBdm3HvI02Yo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Change sampler \n",
        "from diffusers import EulerAncestralDiscreteScheduler, DPMSolverMultistepScheduler, UniPCMultistepScheduler\n",
        "\n",
        "choose_sampler = \"Euler A\" #@param [\"Euler A\", \"DPM++\", \"DPM++ Karras\", \"UniPC\"]\n",
        "\n",
        "if choose_sampler == \"Euler A\":\n",
        "    solver = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "elif choose_sampler == \"DPM++\":\n",
        "    solver = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "elif choose_sampler == \"DPM++ Karras\":\n",
        "    solver = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "    solver.use_karras_sigmas = True\n",
        "elif choose_sampler == \"UniPC\":\n",
        "    solver = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "pipe.scheduler = solver\n",
        "print(f\"Sampler '{choose_sampler}' chosen\")"
      ],
      "metadata": {
        "id": "9i7ZbasUpTh7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE\n",
        "\n",
        "Models loaded from huggingface should have proper VAE. But you also can load VAE from any other repository from [huggingface](https://huggingface.co), just paste their **model_id** and subfolder (usually just \"vae\"). \n",
        "\n",
        "Or you can load it in Automatic111 format and convert using scripts."
      ],
      "metadata": {
        "id": "hEwlf_SQXCyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Load VAE\n",
        "\n",
        "from diffusers import AutoencoderKL\n",
        "\n",
        "vae_id_or_path = \"runwayml/stable-diffusion-v1-5\"  #@param {type: \"string\"}\n",
        "vae_subfolder = \"vae\"    #@param {type: \"string\"}\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"vae_id_or_path\", subfolder=vae_subfolder, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.vae = vae"
      ],
      "metadata": {
        "id": "8jKsuQ9E5eCK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Textual inversions and LoRAs\n",
        "This is work in progress. \n",
        "\n",
        "You can load any textual inversions using \n",
        "```\n",
        "pipe.load_textual_inversion(\"path/to/dir\", weight_name=\"filename.pt\")\n",
        "```\n",
        "To use them, you need to add theit token to a prompt like this `<filename>`.\n",
        "\n",
        "Note, that it seems that if you change VAE after loading textual inversions, using them will degrade generated images."
      ],
      "metadata": {
        "id": "VDQSRzWg5OKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Load textual inversions\n",
        "#@markdown Load every embedding with **.pt** extension from **embeddings** folder.\n",
        "\n",
        "import os\n",
        "\n",
        "for path, subdirs, files in os.walk(\"/content/embeddings/\"):\n",
        "    for name in files:\n",
        "        try:\n",
        "            if os.path.splitext(name)[1] != \".pt\": continue\n",
        "            pipe.load_textual_inversion(path, weight_name=name)\n",
        "            print(path, name)\n",
        "        except: pass"
      ],
      "metadata": {
        "id": "VVU2Rjpb085a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating images"
      ],
      "metadata": {
        "id": "hLmzZmRIZMpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Render UI\n",
        "#@markdown You don't need to run this cell again unless you want to change these settings\n",
        "save_images = True #@param {type:\"boolean\"}\n",
        "display_previewes = True    #@param {type:\"boolean\"}\n",
        "\n",
        "from  StableDiffusionUi.ColabUI.DiffusionPipelineUI import DiffusionPipelineUI\n",
        "\n",
        "ui = DiffusionPipelineUI()\n",
        "ui.render()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oFruEVcl4ODt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to generate images\n",
        "results = ui.generate(pipe, generator)\n",
        "\n",
        "if display_previewes:\n",
        "    ui.display_image_previews(results.images)\n",
        "\n",
        "if save_images:\n",
        "    for image in results.images:\n",
        "        image.save(f\"outputs/txt2img/{output_index:05}.png\")\n",
        "        print(f\"outputs/txt2img/{output_index:05}.png\")\n",
        "        output_index += 1"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y43YLjY7F7NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utils"
      ],
      "metadata": {
        "id": "gthYZKknKsw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image viewer\n",
        "#@markdown Run this cell to view last results\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "slider = widgets.IntSlider(max=len(results.images)-1)\n",
        "\n",
        "def handler(change):\n",
        "    slider.max = len(results.images)-1\n",
        "    if change.new > slider.max: change.new = slider.max\n",
        "    clear_output(wait=True)\n",
        "    display(slider, results.images[change.new])\n",
        "\n",
        "slider.observe(handler, names='value')\n",
        "\n",
        "display(slider, results.images[slider.value])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9vn2Z5tNIAiv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}